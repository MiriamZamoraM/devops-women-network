# DevOps Women Network

Plataforma dise√±ada con las siguientes herramientas:
- Django REST Framework
- Docker
- Kubernetes
- AWS
- Terraform
- CI/CD con GitHub Actions

## üìò Proyecto: DevOps Women Network ‚Äî Kubernetes Learning Journey

Este repositorio documenta mi camino de aprendizaje en DevOps, creando paso a paso un sistema desplegado en Kubernetes. Cada d√≠a incorpora un nuevo concepto y una mejora al proyecto.

---

## üü£ Progreso actual (D√≠a 1‚Äì5)

Hasta este punto he logrado:

### ‚úî 1. Deployment funcional

* Usa imagen `nginx:latest`
* Incluye variables de entorno desde Secrets
* Monta un ConfigMap como volumen en `/usr/share/nginx/html`

### ‚úî 2. ConfigMap operativo

Se usa para servir contenido HTML personalizado dentro de Nginx.

### ‚úî 3. Secret cifrado en base64

Almacena una variable sensible (`DB_PASSWORD`) que se inyecta en el Pod.

### ‚úî 4. Service tipo ClusterIP

Provee networking interno entre Pods.

### ‚úî 5. DNS interno funcionando

Validado mediante un Pod temporal (`test-pod`) con `curl` instalado.

Tuve que:

* reinstalar curl dentro del test-pod
* verificar endpoints del Service
* corregir un `ImagePullBackOff`
* validar coredns en running state

### ‚úî 6. Ingress configurado y funcionando

* Se cre√≥ un archivo ingress.yaml con las reglas de enrutamiento.
* Traefik detect√≥ y aplic√≥ la regla para el host localhost.
* El tr√°fico HTTP externo entra al cl√∫ster y llega al Service hello-service.

Depuraci√≥n avanzada

* Durante este d√≠a se resolvieron problemas relacionados con:
* ImagePullBackOff por fallas de red.
* Reinicio de CoreDNS.
* Re-creaci√≥n de Pods para tomar im√°genes locales.
* Validaci√≥n del funcionament del Ingress con Traefik.


¬°Ingress funcionando y tr√°fico HTTP fluyendo correctamente! üéâ

### ‚úî 7. Reconstrucci√≥n completa del cl√∫ster

* Durante este d√≠a el cl√∫ster present√≥ fallas cr√≠ticas:
* ImagePullBackOff incluso para im√°genes peque√±as
* Pod de pruebas (dns-check) tambi√©n fallaba
* Fallas de DNS interno
* Traefik no pod√≠a enrutar al Service porque no exist√≠an endpoints saludables


La causa: k3d perdi√≥ conectividad externa y DNS interno se corrompi√≥, por lo cual el cluster no pod√≠a descargar im√°genes ni resolver dominios.

#### Soluci√≥n implementada

Se recre√≥ el cl√∫ster desde cero:

- k3d cluster delete dev
- k3d cluster create dev --servers 1 --agents 0 --port "80:80@loadbalancer"


Despu√©s se verific√≥ conectividad con:

- kubectl run dns-check --image=alpine --restart=Never -- sh -c "apk add bind-tools >/dev/null && nslookup google.com"

Una vez confirmado el acceso a Internet, se aplic√≥ nuevamente toda la infraestructura


####  C√≥mo desplegar todo hasta ahora
```
kubectl apply -f infra/k8s/configmap-html.yaml
kubectl apply -f infra/k8s/secret.yaml
kubectl apply -f infra/k8s/deployment.yaml
kubectl apply -f infra/k8s/service.yaml
kubectl apply -f infra/k8s/service-clusterip.yaml
kubectl apply -f infra/k8s/ingress.yaml
```
---
Ver Pods:

```
kubectl get pods
```
---
Ver Service:

```
kubectl get svc
```
---
Probar DNS interno con test-pod:

```
kubectl run test-pod --image=alpine -- sleep 999999
kubectl exec -it test-pod -- sh
apk add curl
curl hello-service
```
---
Resultado

* Pod del Deployment en estado Running
* DNS interno de Kubernetes funcionando
* CoreDNS operativo
* Ingress de Traefik nuevamente accesible en http://localhost
* Endpoints del Service correctos y en estado Ready

---

## üìÇ Estructura del proyecto

```
infra/
  k8s/
    configmap-html.yaml
    deployment.yaml
    secret.yaml
    service.yaml
    service-clusterip.yaml
    ingress.yaml
```
---

### ‚úî 8. Lectura de Logs para saber si hay errores (Del ruido a lo real)

###### En caso de tener problemas con el cluster, pods, y manifiestos, elimanos y volvemos a crear el cluster y aplicamos los manifiestos que hasta aqu√≠ llevamos ü§ì

Desde mi deployment actual:

```
kubectl logs deployment/hello-deployment
```
---

Vayamos a lo importante, leer accesos:

```
kubectl logs deployment/hello-deployment --tail=50
```
---

Escalemos el deployment, listamos los pods y vemos los logs de alguno de ellos:

```
kubectl scale deployment hello-deployment --replicas=2
kubectl get pods
kubectl logs hello-deployment-c58964-46283
```
---

Verifiquemos con Traefik los logs de ingress:

```
kubectl logs -n kube-system deployment/traefik
```
---

Veamos las metricas del cluster:

```
kubectl top nodes
kubectl top pods
```
---

Borremos uno o los pods que tengamos, esto depender√° de la necesidad y para el aprendizaje:

```
kubectl delete pod -l app=hello
```

## üîÆ Siguiente paso: D√≠a 9

Gesti√≥n correcta de configuraciones por entorno:

- ConfigMap vs Secret
- Override por entorno
- Errores comunes en producci√≥n


---

<p align="center">
  <strong>üçÄ Miriam Zamora ¬∑ Backend & DevOps in Progress üçÄ</strong><br/>
  <em>Code. Ship. Repeat.</em><br/>
  <em>Building systems that don‚Äôt break.</em>
</p>